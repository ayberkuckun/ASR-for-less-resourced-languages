{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch\n",
    "import librosa\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "common_voice_test = load_dataset(\"common_voice\", \"hu\", split=\"test[1000:1101]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    mp3_path = os.path.join(os.getcwd(), \"dataset/cv-corpus-8.0-2022-01-19/hu/clips/\", batch[\"path\"])\n",
    "    speech_array, sampling_rate = librosa.load(mp3_path, sr=16_000)\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sentence\"] = batch[\"sentence\"].upper()\n",
    "    return batch\n",
    "\n",
    "test_dataset = common_voice_test.map(speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_ID_IT = \"gchhablani/wav2vec2-large-xlsr-it\"\n",
    "MODEL_ID_FI = \"aapot/wav2vec2-xlsr-1b-finnish-v2\"\n",
    "MODEL_ID_CS = \"sammy786/wav2vec2-xlsr-czech\"\n",
    "\n",
    "model_ids = [MODEL_ID_IT, MODEL_ID_FI, MODEL_ID_CS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "\n",
    "for model_id in model_ids:\n",
    "    predicted_sentences = []\n",
    "\n",
    "    processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(model_id)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for i in tqdm(range(int(len(test_dataset[\"speech\"]) / 5))):\n",
    "        batch = test_dataset[\"speech\"][i*5:(i+1)*5]\n",
    "\n",
    "        inputs = processor(batch, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        inputs.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs.input_values).logits\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        predicted_sentences += processor.batch_decode(predicted_ids)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if model_id == MODEL_ID_IT:\n",
    "        predicted_sentences_it = predicted_sentences\n",
    "    if model_id == MODEL_ID_FI:\n",
    "        predicted_sentences_fi = predicted_sentences\n",
    "    if model_id == MODEL_ID_CS:\n",
    "        predicted_sentences_cs = predicted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "it_to_hu_dict = {\n",
    "                 'sho' : 'so',\n",
    "                 'ot' : 'olt',\n",
    "\n",
    "                 \"i l\" : \"ill\",\n",
    "                 \"s e\" : \"sze\",\n",
    "                 \"la v\" : \"levél\",\n",
    "                 \"las\" : \"l s\",\n",
    "                 \"t a g\" : \"te g\",\n",
    "                 \" ave\" : \"neve\",\n",
    "                 \"ra s\" : \"res\",\n",
    "                 \"at at\" : \"etet\",\n",
    "                 \"ba na\" : \"báná\",\n",
    "                 \" pal\" : \"pál\",\n",
    "                 \"ida \" : \"ide \",\n",
    "                 \"nas\" : \"nás\",\n",
    "                 \"na\" : \"ne\",\n",
    "                 \"mar\" : \"már\",\n",
    "                 \"ma\" : \"me\",\n",
    "                 \"lan\" : \"len\",\n",
    "                 \"lal\" : \"lől\",\n",
    "                 \"lad\" : \"lód\",\n",
    "                 \"lat\" : \"lát\",\n",
    "                 \"har\" : \"hár\",\n",
    "                 \"hall\" : \"holl\",\n",
    "                 \"fal\" : \"fel\",\n",
    "                 \"fas\" : \"fés\",\n",
    "                 \"rag\" : \"rág\",\n",
    "                 \"ran\" : \"ren\",\n",
    "                 \"tan \" : \"tán \",\n",
    "                 \"kat\" : \"ket\",\n",
    "                 \"gat\" : \"get\",\n",
    "                 \"al\" : \"ál\",\n",
    "                 \" co\" : \" a ko\",\n",
    "                 \"nci\" : \"n ki\",\n",
    "                 \"eci\" : \"e és i\",\n",
    "                 \"ece\" : \"ese\",\n",
    "                 \"ice\" : \"ise\",\n",
    "                 \"tad \" : \"tat \",\n",
    "                 \"edi\" : \"egyi\",\n",
    "                 \"ke\" : \"ké\",\n",
    "                 \"fe\" : \"fé\",\n",
    "                 \"te\" : \"té\",\n",
    "                 \"of\" : \"og\",\n",
    "                 \" is\" : \" és\",\n",
    "                 \" ti\" : \" tü\",\n",
    "                 \"ti\" : \"té\",\n",
    "                 \"mi\" : \"mű\",\n",
    "                 \"ni\" : \"ny\",\n",
    "                 \"di\" : \"dí\",\n",
    "                 \"ria\" : \"rja\",\n",
    "                 \"vi\" : \"vé\",\n",
    "                 \"bí\" : \"by\",\n",
    "                 \"on \" : \"om\",\n",
    "                 \"tan\" : \"tam\",\n",
    "                 \"elv\" : \"enj v\",\n",
    "                 \" mo\" : \" bo\",\n",
    "                 \"ami\" : \"a vi\",\n",
    "                 \" to\" : \" tú\",\n",
    "                 \"lo w\" : \"lú\",\n",
    "                 \" om\" : \"am\",\n",
    "                 \"lo\" : \"la\",\n",
    "                 \"bo\" : \"ba\",\n",
    "                 \"to\" : \"ta\",\n",
    "                 \"no\" : \"na\",\n",
    "                 \"mo\" : \"ma\",\n",
    "                 \"ho\" : \"ha\",\n",
    "                 \"do\" : \"da\",\n",
    "                 \"jo\" : \"ja\",\n",
    "                 \"vo\" : \"va\",\n",
    "                 \"tò\" : \"ta\",\n",
    "                 \"nò\" : \"na\",\n",
    "                 \" pe\" : \" be\",\n",
    "                 \"pt\" : \"bt\",\n",
    "                 \"ars\" : \"a es\",\n",
    "                 \"pr \" : \"pe\",\n",
    "                 \"or\" : \"ol\",\n",
    "                 \"ase\" : \"az e\",\n",
    "                 \"at \" : \"ad \",\n",
    "                 \"ata\" : \"ada\",\n",
    "                 \"u y\" : \"ol\",\n",
    "                 \"nut\" : \"nőt\",\n",
    "                 \"nu\" : \"yű \",\n",
    "                 \" u\" : \" ü\",\n",
    "                 \"sun\" : \"szűn\",\n",
    "                 \"ku\" : \"kö\",\n",
    "                 \"tu\" : \"tó\",\n",
    "                 \"yu\" : \"yó\",\n",
    "                 \"hu\" : \"hó\",\n",
    "                 \"svi\" : \"s i\",\n",
    "                 \"ava\" : \"aba\",\n",
    "                 \"two\" : \"t vo\",\n",
    "                 \"twa\" : \"tóa\",\n",
    "                 \"axa\" : \"a ka\",\n",
    "                 \"ey\" : \"ei\",\n",
    "                 \"by\" : \"bi\",\n",
    "                 'sh ' : 's ',\n",
    "                 #'e' : 'é',\n",
    "                 #'ar' : 'á',\n",
    "                 'ia' : 'e',\n",
    "                 #' a' : 'e',\n",
    "                 #'c' : 's',\n",
    "                 #'p' : 'b',\n",
    "                 #'n' : 'm',\n",
    "                 \" ge\" : \" le\",\n",
    "                 \"qué\" : \"ke\",\n",
    "                \"x\" : \"ks\",\n",
    "                \"q\" : \"k\",\n",
    "                \" è \" : \" e\",\n",
    "\n",
    "                \"sse\" : \"s se\",\n",
    "                \"ss\" : \"s\",\n",
    "                \"vv\" : \"v\",\n",
    "                \"vige\" : \"vide\",\n",
    "\n",
    "                \"gn\" : \"ny\",\n",
    "                \"zs\" : \"s\",\n",
    "                \"ghi\" : \"gi\",\n",
    "                \"ge\" : \"dzse\",\n",
    "                \"ghe\" : \"ge\",\n",
    "                \"chia\" : \"tya\",\n",
    "                \"cha\" : \"sa\",\n",
    "                \"san \" : \"sam \",\n",
    "                \"chi\" : \"ki\",\n",
    "                \"che \" : \"s \",\n",
    "                \"che\" : \"ke\",\n",
    "\n",
    "                \"cr\" : \"kr\",\n",
    "                \"ca\" : \"ka\",\n",
    "                \"co\" : \"ko\",\n",
    "                \"ci\" : \"cs\",\n",
    "                \"sice\" : \"sk\",\n",
    "\n",
    "                \"ce\" : \"s\",\n",
    "                \"cu\" : \"ku\",\n",
    "                \"sz\" : \"zs\",\n",
    "                \" z\" : \" dz\",\n",
    "\n",
    "                \"ra\" : \"rá\",\n",
    "                \" gr\" : \" l\",\n",
    "\n",
    "                \"mo\" : \"mú\",\n",
    "                \"úré\" : \"úlé\",\n",
    "                \"úre\" : \"úlé\",\n",
    "                \"aro\" : \"ajlo\",\n",
    "                \"edi\" : \"egy\",\n",
    "                \"khe\" : \"ker\",\n",
    "                \"sui\" : \"ső\",\n",
    "                \"ck\" : \"t\",\n",
    "                \"ti \" : \"t \",\n",
    "                \" y\" : \" j\",\n",
    "                \"st\" : \"zt\",\n",
    "                \"sh \" : \"s \",\n",
    "                \" e\" : \" é\",\n",
    "                \" ov \" : \" ov\",\n",
    "                \" cso \" : \"cso \",\n",
    "                \" apa\" : \"apa\",\n",
    "\n",
    "                \"sp\" : \"scap\",\n",
    "                \" ká\" : \" ha\",\n",
    "                \" me\" : \" nem\",\n",
    "\n",
    "                \" ke\" : \" ki\",\n",
    "                \"ey\" : \"é\",\n",
    "                \"ai m\" : \"ány \",\n",
    "                \"eno\" : \"ána\",\n",
    "                \"lz\" : \"lc\",\n",
    "                \"dop\" : \"dob\",\n",
    "                \"é sch\" : \"és\",\n",
    "                \"sel\" : \"szél\",\n",
    "                \"li\" : \"lé\",\n",
    "                \"de \" : \"d \",\n",
    "                \"viz\" : \"vis\",\n",
    "                \"n'\" : \"nt\",\n",
    "                \"erel\" : \"erül\",\n",
    "                \"ig\" : \"ég\",\n",
    "                \" of \" : \" ov \",\n",
    "                \"bi\" : \"bő\",\n",
    "                \"be\" : \"bi\",\n",
    "                \" oz\" : \" az\",\n",
    "                \" the\" : \" de\",\n",
    "                \"ria\" : \"re\",\n",
    "                \" is \" : \" és \",\n",
    "                \"bo\" : \"ba\",\n",
    "                \" ob\" : \" ab\",\n",
    "                \" ka\" : \" ha\",\n",
    "                \"qel\" : \"or\",\n",
    "                \"koni\" : \"vagy\",\n",
    "                \" la\" : \" ra\",\n",
    "                \"raika\" : \"rajta\",\n",
    "\n",
    "                \"egya \" : \"egya\",\n",
    "                \"aan\" : \"aan \",\n",
    "                \" ker \" : \" ker\",\n",
    "                \"rső \" : \"rső\",\n",
    "                \"ò s \" : \"òs \",\n",
    "                \"ò\" : \"a\",\n",
    "                \"dri \" : \"dri\",\n",
    "                \" dov\" : \"do v\",\n",
    "                \" v \" : \" v\",\n",
    "                \" ve \" : \" ve\",\n",
    "                \" di \" : \"di \",\n",
    "                \" dod \" : \"dod \",\n",
    "                \" an \"  : \"an\",\n",
    "                \"zto \" : \"zto\",\n",
    "                \"sanok\" : \"san ok\",\n",
    "                \"kitn\" : \"kit n\",\n",
    "                \" né \" : \" né\",\n",
    "                \" lon \" : \"lon \",\n",
    "                \"baba\" : \" baba \",\n",
    "                \"ugi \" : \"ugi\",\n",
    "                \" rel\" : \"rel\",\n",
    "                 }\n",
    "\n",
    "fi_to_hu_dict = {\" e \" : \" egy \",\n",
    "\n",
    "                 \"sii\" : \"zé\",\n",
    "                 \"iis\": \"íz \",\n",
    "                 \"tää \" : \"tem\",\n",
    "                 \"aan\" : \"eg\",\n",
    "\n",
    "                 \"obro\" : \"ogo\",\n",
    "                 \"lui\" : \"gy\",\n",
    "                 \"sat\" : \"set\",\n",
    "                 \"a m\" : \"em\",\n",
    "                 \"esa\" : \"ese\",\n",
    "                 \"oma\" : \"omo\",\n",
    "                 \"sal\" : \"sál\",\n",
    "                 \" j\" : \" ly\",\n",
    "                 \"ik \" : \"ig \",\n",
    "                 \"aja\" : \"agya\",\n",
    "                 \"eje\" : \"egye\",\n",
    "                 \"iki\" : \"iti\",\n",
    "                 \"eli\" : \"edi\",\n",
    "                 \"to \" : \"ta \",\n",
    "                 \"t o\" : \"t a\",\n",
    "                 \"a o\" : \"a a\",\n",
    "                 #\" t\" : \" d\",\n",
    "                 \"kt\" : \"k v\",\n",
    "                 \"otk\" : \"ogy k\",\n",
    "                 \"lys\" : \"lyő\",\n",
    "                 \"un \" :  \"om \",\n",
    "                 \"aus\" : \"ajóz\",\n",
    "                 \"ele\" : \"ere\",\n",
    "                 \"uji\" : \"ogyi\",\n",
    "                 \"uju\" : \"olyo\",\n",
    "                 \"ä t\" : \"alt\",\n",
    "                 'shi' : 'si',\n",
    "                 'vuo' : 'vo',\n",
    "                 \"kon\" : \"kön\",\n",
    "                 \"ja \" : \"je \",\n",
    "\n",
    "                 'ää' : 'á',\n",
    "                 \"aa\" : \"e\",\n",
    "                 \"oi\" : \"a e\",\n",
    "                 'uu' : 'ó ',\n",
    "                 'ii' : 'é',\n",
    "                 \"oo\" : \"ó\",\n",
    "                 \"ee\" : \"é\",\n",
    "                 \"ää\" : \"á\",\n",
    "                 \"yy\" : \"ő\",\n",
    "                 \"nn\" : \"nd\",\n",
    "\n",
    "                 'ä ' : 'e',\n",
    "                 ' s' : ' cs',\n",
    "                 'e ' : 'egy ',\n",
    "                 ' m' : ' am',\n",
    "                 't ' : 'tt ',\n",
    "                 'sh ' : 's ',\n",
    "                 'a ' : 'ak ',\n",
    "                 'e ': 'ett ',\n",
    "                 'i ' : 'is ',\n",
    "                 \"mi \" : \"mű \",\n",
    "                 \"io \" : \"ia \",\n",
    "                 \"ot \" : \"od\",\n",
    "\n",
    "                 'hi' : 'é',\n",
    "                 'sa' : 'sza',\n",
    "                 'lm' : 'lam',\n",
    "                 'ot' : 'olt',\n",
    "                 #'j' : 'gy',\n",
    "\n",
    "                 \"äl\" : \"el\",\n",
    "                 \"lä\" : \"le\",\n",
    "                 \"tä\" : \"te\",\n",
    "                 \"jä\" : \"já\",\n",
    "                 \"ät\" : \"alt\",\n",
    "                 \"mä\" : \"me\",\n",
    "                 \"nä\" : \"ne\",\n",
    "                 \"kä\" : \"ke\",\n",
    "                 \"än\" : \"en\",\n",
    "                 \"hä\" : \"he\",\n",
    "                 \"sä\" : \"se\",\n",
    "                 \"dä\" : \"de\",\n",
    "                 \"fä\" : \"fe\",\n",
    "                 \"bä\" : \"be\",\n",
    "                 \"ah\" : \"oh\",\n",
    "                 \"la\" : \"lá\",\n",
    "                 \"ma\" : \"má\",\n",
    "                 \"ra\" : \"rá\",\n",
    "                 \"as\" : \"es\",\n",
    "                 \"al\" : \"el\",\n",
    "                 \"ta\" : \"tá\",\n",
    "                 \"ke\" : \"kö\",\n",
    "                 \"te\" : \"tá\",\n",
    "                 \"me\" : \"mé\",\n",
    "                 \"ve\" : \"vö\",\n",
    "                 #\" d\" : \"t\",\n",
    "                 \"se\" : \"sé\",\n",
    "                 \"hi\" : \"hí\",\n",
    "                 \"il\" : \"él\",\n",
    "                 \"li\" : \"lé\",\n",
    "                 \"ki\" : \"ké\",\n",
    "                 \"ik\" : \"ék\",\n",
    "                 \"ti\" : \"té\",\n",
    "                 \"si\" : \"sí\",\n",
    "                 \"vi\" : \"ve\",\n",
    "                 \"ri\" : \"ré\",\n",
    "                 \"ai\" : \"aj\",\n",
    "                 \"ig\" : \"ég\",\n",
    "                 \"gi\" : \"gé\",\n",
    "                 \"fi\" : \"fé\",\n",
    "                 \"ek\" : \"eg\",\n",
    "                 \"n \" : \"m\",\n",
    "                 \"no\" : \"na\",\n",
    "                 \"ko\" : \"ka\",\n",
    "                 \"mo\" : \"ma\",\n",
    "                 \"bo\" : \"ba\",\n",
    "                 \"ob\" : \"öb\",\n",
    "                 \"ol\" : \"al\",\n",
    "                 \"lo\" : \"la\",\n",
    "                 \"os\" : \"oz\",\n",
    "                 \"as\" : \"az\",\n",
    "                 \"is\" : \"iz\",\n",
    "                 \"ts\" : \"cs\",\n",
    "                 \"nt\" : \"nd\",\n",
    "                 \"ut\" : \"ud\",\n",
    "                 \"tu\" : \"to\",\n",
    "                 \"lu\" : \"lo\",\n",
    "                 \"iu\" : \"ió\",\n",
    "                 \"ku\" : \"ko\",\n",
    "                 \"ru\" : \"ro\",\n",
    "                 \"ly\" : \"lő\",\n",
    "                 \"ky\" : \"kö\",\n",
    "                 \"sy\" : \"szű\",\n",
    "                 \"yi \" : \"ő\",\n",
    "                 \"vä\" : \"be\",\n",
    "                 \"ah\" : \"á\",\n",
    "                 \"ha\" : \"á\",\n",
    "\n",
    "                 }\n",
    "\n",
    "cz_to_hu_dict = {\"mň\" : \"meň\",\n",
    "                 \"č\" : \"cs\",\n",
    "                 \"ď'\" : \"gy\",\n",
    "                 \"ě\" : \"é\",\n",
    "                 \"ň\" : \"ny\",\n",
    "                 \"š\" : \"s\",\n",
    "                 \"ř\" : \"cs\",\n",
    "                 \"ů\" : \"ú\",\n",
    "                 \"ý\" : \"i\",\n",
    "                 \"ž\" : \"s\",\n",
    "                 \"a c\" : \"ák\",\n",
    "                 \"rla\" : \"rlá\",\n",
    "                 \"ice\" : \"ike\",\n",
    "                 \"aca\" : \"ajla\",\n",
    "                 \"to b\" : \"több\",\n",
    "                 \"vo n\" : \"van\",\n",
    "                 \"avi\" : \"aki\",\n",
    "                 \"gvr\" : \"gér\",\n",
    "                 \" c\" : \" k\",\n",
    "                 \" co\" : \" so\",\n",
    "                 \" js\" : \" cs\",\n",
    "                 \"ic \" : \"ik \",\n",
    "                 \"d \" : \"t \",\n",
    "                 \"e \" : \"a \",\n",
    "                 \"j \" : \"i \",\n",
    "                 \" j\" : \"gy\",\n",
    "                 \"f \" : \"k \",\n",
    "                 \" w\" : \" v\",\n",
    "                 \"ky\" : \"k i\",\n",
    "                 \"y \" : \"ig \",\n",
    "                 \"tw\" : \"t v\",\n",
    "                 \" r\" : \" f\",\n",
    "                 \" s\" : \" z\",\n",
    "                 \"ar\" : \"ár\",\n",
    "                 \"dá\" : \"da\",\n",
    "                 \"ma\" : \"me\",\n",
    "                 \"al\" : \"el\",\n",
    "                 \"la\" : \"le\",\n",
    "                 \"na\" : \"ne\",\n",
    "                 \"pa\" : \"pá\",\n",
    "                 \"sa\" : \"se\",\n",
    "                 \"ka\" : \"ke\",\n",
    "                 \"ta\" : \"te\",\n",
    "                 \"ha\" : \"he\",\n",
    "                 \"ra\" : \"re\",\n",
    "                 \"ga\" : \"ge\",\n",
    "                 \"ic\" : \"ik\",\n",
    "                 \"ch\" : \"gh\",\n",
    "                 \"mc\" : \"mk\",\n",
    "                 \"nc\" : \"nk\",\n",
    "                 \"uc \" : \"udsz \",\n",
    "                 \"ld\" : \"lt\",\n",
    "                 \"nd\" : \"nt\",\n",
    "                 \"ke\" : \"cé\",\n",
    "                 \"ce\" : \"cá\",\n",
    "                 \"ni\" : \"né\",\n",
    "                 \"ei\" : \"é\",\n",
    "                 \"lh \" : \"lt \",\n",
    "                 \"vi\" : \"vé\",\n",
    "                 \"il\" : \"él\",\n",
    "                 \"li\" : \"lé\",\n",
    "                 \"ti\" : \"té\",\n",
    "                 \"mi\" : \"mé\",\n",
    "                 \"ei\" : \"eí\",\n",
    "                 \"ji\" : \"é\",\n",
    "                 \"ok\" : \"ók\",\n",
    "                 \"jo\" : \"ja\",\n",
    "                 \"vo\" : \"va\",\n",
    "                 \"ov\" : \"av\",\n",
    "                 \"lo\" : \"la\",\n",
    "                 \"to\" : \"ta\",\n",
    "                 \"bo\" : \"ba\",\n",
    "                 \"do\" : \"dó\",\n",
    "                 \"ho\" : \"ha\",\n",
    "                 \"no\" : \"na\",\n",
    "                 \"go\" : \"go\",\n",
    "                 \"em\" : \"en\",\n",
    "                 \"om\" : \"on\",\n",
    "                 \"lu\" : \"lő\",\n",
    "                 \"du\" : \"dó\",\n",
    "                 \"ru\" : \"ro\",\n",
    "                 \"yu\" : \"yó\",\n",
    "                 \"ny\" : \"ni\",\n",
    "                 \"os\" : \"oz\",\n",
    "                 \"su\" : \"ső\",\n",
    "                 \"tu\" : \"ú\",\n",
    "                 \"ku\" : \"ko\",\n",
    "                 \"nu\" : \"nő\",\n",
    "                 'o ' : 'a',\n",
    "                 'a ' : 'e',\n",
    "                 'l ' : 'lt ',\n",
    "                 'ď' : 'gy',\n",
    "                 'ot' : 'olt',\n",
    "                 'nm' : 'nem',\n",
    "                 #'c' : 'k',\n",
    "                 'č' : 'cs',\n",
    "                 'ň' : 'ny',\n",
    "                 'se' : 'sze',\n",
    "                 'š' : 's',\n",
    "                 #'j' : 'i',\n",
    "                 #'w' : 'v',\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "it_spellcheck = []\n",
    "fi_spellcheck = []\n",
    "cz_spellcheck = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, predicted_sentence in enumerate(zip(predicted_sentences_it, predicted_sentences_fi, predicted_sentences_cs)):\n",
    "    nsent_it = \" \" + predicted_sentence[0] + \" \"\n",
    "    for ind_it, k_it in enumerate(it_to_hu_dict.keys()):\n",
    "      if k_it in (\" \" + predicted_sentence[0] + \" \"): #avoids changes being made from changes\n",
    "        nsent_it = nsent_it.replace(k_it, it_to_hu_dict[k_it])\n",
    "        #print(f\"Change{ind_it}: {nsent_it} --- {k_it} -> {it_to_hu_dict[k_it]}\")\n",
    "\n",
    "    nsent_fi = \" \" + predicted_sentence[1] + \" \"\n",
    "    for ind_fi, k_fi in enumerate(fi_to_hu_dict.keys()):\n",
    "      if k_fi in (\" \" + predicted_sentence[1] + \" \"):\n",
    "        nsent_fi = nsent_fi.replace(k_fi, fi_to_hu_dict[k_fi])\n",
    "        #print(f\"Change{ind_fi}: {nsent_fi} --- {k_fi} -> {fi_to_hu_dict[k_fi]}\")\n",
    "\n",
    "    nsent_cz = \" \" + predicted_sentence[2] + \" \"\n",
    "    for ind_cz, k_cz in enumerate(cz_to_hu_dict.keys()):\n",
    "      if k_cz in (\" \" + predicted_sentence[2] + \" \"):\n",
    "        nsent_cz = nsent_cz.replace(k_cz, cz_to_hu_dict[k_cz])\n",
    "        #print(f\"Change{ind_cz}: {nsent_cz} --- {k_cz} -> {cz_to_hu_dict[k_cz]}\")\n",
    "\n",
    "    it_spellcheck.append(nsent_it)\n",
    "    fi_spellcheck.append(nsent_fi)\n",
    "    cz_spellcheck.append(nsent_cz)\n",
    "\n",
    "    # print(\"-\" * 100)\n",
    "    # print(\"Reference:\", test_dataset[i][\"sentence\"].lower())\n",
    "    # print(\"Italian Prediction1:\", predicted_sentence[0])\n",
    "    # print(\"Italian Prediction2:\", nsent_it)\n",
    "    # print(\"Finnish Prediction1:\", predicted_sentence[1])\n",
    "    # print(\"Finnish Prediction2:\", nsent_fi)\n",
    "    # print(\"Czech Prediction1:\", predicted_sentence[2])\n",
    "    # print(\"Czech Prediction2:\", nsent_cz)\n",
    "    # print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_sentences_fi_list = np.empty(len(predicted_sentences_fi)).tolist()\n",
    "predicted_sentences_it_list = np.empty(len(predicted_sentences_it)).tolist()\n",
    "predicted_sentences_cs_list = np.empty(len(predicted_sentences_cs)).tolist()\n",
    "\n",
    "for i in range(len(predicted_sentences_it)):\n",
    "  predicted_sentences_fi_list[i] = predicted_sentences_fi[i].lower().split()\n",
    "  predicted_sentences_it_list[i] = predicted_sentences_it[i].lower().split()\n",
    "  predicted_sentences_cs_list[i] = predicted_sentences_cs[i].lower().split()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=5, prefix_length=8, count_threshold=10)\n",
    "dictionary_path = \"lm/hu_50k.txt\"\n",
    "bigram_path = \"lm/final_bigrams1.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sym_spell.load_dictionary(dictionary_path, 0, 1)\n",
    "sym_spell.load_bigram_dictionary(bigram_path, 0, 2, encoding=\"utf8\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "lanugage_model_input_fi = []\n",
    "\n",
    "for sentence in predicted_sentences_fi_list:\n",
    "  spell_checked_list_fi = [[] for _ in range(len(sentence))]\n",
    "\n",
    "  for no, word in enumerate(sentence):\n",
    "    suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=3, include_unknown=True)\n",
    "    for suggestion in suggestions:\n",
    "      spell_checked_list_fi[no].append(suggestion.term)\n",
    "\n",
    "  all_combinations_fi = list(itertools.product(*spell_checked_list_fi))\n",
    "\n",
    "  spell_checked_sentences_fi = []\n",
    "\n",
    "  for combination in all_combinations_fi:\n",
    "    spell_checked_sentences_fi.append(' '.join(word for word in combination))\n",
    "\n",
    "  lanugage_model_input_fi.append(spell_checked_sentences_fi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "lanugage_model_input_it = []\n",
    "\n",
    "for sentence in predicted_sentences_it_list:\n",
    "  spell_checked_list_it = [[] for _ in range(len(sentence))]\n",
    "\n",
    "  for no, word in enumerate(sentence):\n",
    "    suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=3, include_unknown=True)\n",
    "    for suggestion in suggestions:\n",
    "      spell_checked_list_it[no].append(suggestion.term)\n",
    "\n",
    "  all_combinations_it = list(itertools.product(*spell_checked_list_it))\n",
    "\n",
    "  spell_checked_sentences_it = []\n",
    "\n",
    "  for combination in all_combinations_it:\n",
    "    spell_checked_sentences_it.append(' '.join(word for word in combination))\n",
    "\n",
    "  lanugage_model_input_it.append(spell_checked_sentences_it)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "lanugage_model_input_cs = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for sentence in predicted_sentences_cs_list:\n",
    "  spell_checked_list_cs = [[] for _ in range(len(sentence))]\n",
    "\n",
    "  for no, word in enumerate(sentence):\n",
    "    suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2, include_unknown=True)\n",
    "    for suggestion in suggestions:\n",
    "      spell_checked_list_cs[no].append(suggestion.term)\n",
    "\n",
    "  all_combinations_cs = list(itertools.product(*spell_checked_list_cs))\n",
    "\n",
    "  spell_checked_sentences_cs = []\n",
    "\n",
    "  for combination in all_combinations_cs:\n",
    "    spell_checked_sentences_cs.append(' '.join(word for word in combination))\n",
    "\n",
    "  lanugage_model_input_cs.append(spell_checked_sentences_cs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import kenlm\n",
    "\n",
    "model = kenlm.LanguageModel(\"lm/hu_5gram_lm.bin\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "final_transcript_fi = []\n",
    "\n",
    "for permuted_sentences in lanugage_model_input_fi:\n",
    "  scores_fi = []\n",
    "\n",
    "  for spell_checked_sentence in permuted_sentences:\n",
    "    scores_fi.append(model.score(spell_checked_sentence))\n",
    "\n",
    "  best_sentence_index_fi = np.argmax(scores_fi)\n",
    "\n",
    "  final_transcript_fi.append(permuted_sentences[best_sentence_index_fi])\n",
    "\n",
    "final_transcript_it = []\n",
    "\n",
    "for permuted_sentences in lanugage_model_input_it:\n",
    "  scores_it = []\n",
    "\n",
    "  for spell_checked_sentence in permuted_sentences:\n",
    "    scores_it.append(model.score(spell_checked_sentence))\n",
    "\n",
    "  best_sentence_index_it = np.argmax(scores_it)\n",
    "\n",
    "  final_transcript_it.append(permuted_sentences[best_sentence_index_it])\n",
    "\n",
    "final_transcript_cs = []\n",
    "\n",
    "for permuted_sentences in lanugage_model_input_cs:\n",
    "  scores_cs = []\n",
    "\n",
    "  for spell_checked_sentence in permuted_sentences:\n",
    "    scores_cs.append(model.score(spell_checked_sentence))\n",
    "\n",
    "  best_sentence_index_cs = np.argmax(scores_cs)\n",
    "\n",
    "  final_transcript_cs.append(permuted_sentences[best_sentence_index_cs])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i, predicted_sentence in enumerate(zip(final_transcript_fi, final_transcript_it, final_transcript_cs)):\n",
    "#   print(\"-\" * 100)\n",
    "#   print(\"Reference:\", final_ref_proccesed[i].lower())\n",
    "#   print(\"FI Prediction:\", predicted_sentence[0].lower())\n",
    "#   print(\"IT Prediction:\", predicted_sentence[1].lower())\n",
    "#   print(\"CS Prediction:\", predicted_sentence[2].lower())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# End Try"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sort_dict(dictionary):\n",
    "    sorted_dict = {k: dictionary[k] for k in\n",
    "                   sorted(dictionary, key=dictionary.get, reverse=True)}\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def damerau_levenshtein_distance(word1, word2):\n",
    "    distances = {}  # creates array, in dictionary form, in order to calculate d-l distance\n",
    "    for w1 in range(-1, len(word1) + 1):  # creates first row values\n",
    "        distances[(w1, -1)] = w1 + 1\n",
    "    for w2 in range(-1, len(word2) + 1):  # creates first column values\n",
    "        distances[(-1, w2)] = w2 + 1\n",
    "    for w1 in range(len(word1)):  # creates values for the rest of the \"array\"\n",
    "        for w2 in range(len(word2)):\n",
    "            if word1[w1] == word2[w2]:\n",
    "                point = 0\n",
    "            else:\n",
    "                point = 1\n",
    "            a = distances[(w1, w2 - 1)] + 1\n",
    "            b = distances[(w1 - 1, w2)] + 1\n",
    "            c = distances[(w1 - 1, w2 - 1)] + point\n",
    "            distances[(w1, w2)] = min(min(a, b), min(b, c))\n",
    "            if w1 and w2 and word1[w1] == word2[w2 - 1] and word1[w1 - 1] == word2[w2]:\n",
    "                d = distances[(w1, w2)]\n",
    "                e = distances[(w1 - 2, w2 - 2)] + point\n",
    "                distances[(w1, w2)] = min(d, e)\n",
    "    return int(distances[(len(word1) - 1, len(word2) - 1)])  # returns final \"array\" value which gives the d-l distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_in_gram_dict(sorted_potentials, gram_dictionary, final_sentence):\n",
    "  new_potentials = dict()\n",
    "  gram_keys = list(gram_dictionary.keys())\n",
    "  for potential_k in sorted_potentials.keys():\n",
    "    for gram_key in gram_keys:\n",
    "      if potential_k == gram_key[-1] and final_sentence[-1] == gram_key[-2]:\n",
    "        new_potentials[potential_k] = gram_dictionary[gram_key]\n",
    "  if len(new_potentials) > 0:\n",
    "    sorted_new_potentials = sort_dict(new_potentials)\n",
    "    sorted_pot_keys = list(sorted_new_potentials.keys())\n",
    "    return sorted_pot_keys[0]\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unigram_dict = {}\n",
    "with open(\"lm/hu_50k.txt\") as f:\n",
    "    for line in f:\n",
    "       (key, val) = line.split()\n",
    "       unigram_dict[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bigram_dict = {}\n",
    "with open(\"lm/final_bigrams1.txt\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "       temp = line.split()\n",
    "       bigram_dict[temp[0], temp[1]] = temp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def spellcheck(sent):\n",
    "    nsent = []\n",
    "\n",
    "    for input_word in sent:\n",
    "      if input_word in unigram_dict.keys():\n",
    "          nsent.append(input_word)\n",
    "      else:\n",
    "        potential_words = dict()\n",
    "        for hu_word in unigram_dict.keys():\n",
    "          dist = damerau_levenshtein_distance(input_word, hu_word)\n",
    "          if dist < 3: #we can edit this as necessary\n",
    "            potential_words[hu_word] = unigram_dict[hu_word]\n",
    "\n",
    "        sorted_potents = sort_dict(potential_words)\n",
    "        sorted_pot_keys = list(sorted_potents.keys())\n",
    "\n",
    "        if len(potential_words) > 0:\n",
    "          if len(nsent) > 1:\n",
    "            tri_bis = check_in_gram_dict(sorted_potents, bigram_dict, nsent)\n",
    "            if tri_bis == False:\n",
    "              nsent.append(sorted_pot_keys[0])\n",
    "            else:\n",
    "              nsent.append(tri_bis)\n",
    "          else:\n",
    "            nsent.append(sorted_pot_keys[0])\n",
    "        else:\n",
    "          nsent.append(input_word)\n",
    "\n",
    "    return \" \".join(nsent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "it = []\n",
    "fi = []\n",
    "cs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for sentence in it_spellcheck:\n",
    "    sent_it = sentence.split()\n",
    "    it.append(spellcheck(sent_it))\n",
    "\n",
    "for sentence in fi_spellcheck:\n",
    "    sent_fi = sentence.split()\n",
    "    fi.append(spellcheck(sent_fi))\n",
    "\n",
    "for sentence in cz_spellcheck:\n",
    "    sent_cs = sentence.split()\n",
    "    cs.append(spellcheck(sent_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ref = [x.lower() for x in test_dataset[\"sentence\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def choice_dict(choices):\n",
    "  count_dict = defaultdict(int)\n",
    "\n",
    "  for item in choices:\n",
    "    if isinstance(item, str):\n",
    "      count_dict[item] += 1\n",
    "    else:\n",
    "      for c in item:\n",
    "        count_dict[c] += 1\n",
    "\n",
    "  return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_choice(the_dict):\n",
    "  sorted_count = sort_dict(the_dict)\n",
    "  keys = list(sorted_count.keys())\n",
    "  values = list(sorted_count.values())\n",
    "\n",
    "  if len(values) > 1:\n",
    "    for i, v in enumerate(values):\n",
    "      if i == 0:\n",
    "        if v == values[i+1]:\n",
    "          return str(random.choice((keys[0], keys[1]))) #currently returns random choice from the tied keys\n",
    "        else:\n",
    "          return keys[0]\n",
    "  else:\n",
    "    return keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_processing(it_sent, fi_sent, cz_sent=None, reference=None): #takes strings as input, only req 2 langs #USE THIS ONE\n",
    "  l12_sent = []\n",
    "\n",
    "  final_output = ' '\n",
    "\n",
    "  if cz_sent: #when 3 usable sents\n",
    "    it_fi = SequenceMatcher(None, it_sent, fi_sent)\n",
    "    fi_cz = SequenceMatcher(None, fi_sent, cz_sent)\n",
    "    cz_it = SequenceMatcher(None, cz_sent, it_sent)\n",
    "\n",
    "    it_fi_sent = []\n",
    "    fi_cz_sent = []\n",
    "    cz_it_sent = []\n",
    "\n",
    "    for op, a_start, a_end, b_start, b_end in it_fi.get_opcodes():\n",
    "      frag_it = {it_sent[a_start:a_end]}\n",
    "      frag_fi = {fi_sent[b_start:b_end]}\n",
    "\n",
    "      if op == \"equal\":\n",
    "        for item in frag_it:\n",
    "          it_fi_sent.append(item)\n",
    "      elif op == \"replace\":\n",
    "        for i in frag_it:\n",
    "          for j in frag_fi:\n",
    "            it_fi_sent.append((i,j))\n",
    "\n",
    "    for op, a_start, a_end, b_start, b_end in fi_cz.get_opcodes():\n",
    "      frag_fi = {fi_sent[a_start:a_end]}\n",
    "      frag_cz = {cz_sent[b_start:b_end]}\n",
    "\n",
    "      if op == \"equal\":\n",
    "        for item in frag_fi:\n",
    "          fi_cz_sent += item\n",
    "      elif op == \"replace\":\n",
    "        for i in frag_fi:\n",
    "          for j in frag_cz:\n",
    "            fi_cz_sent.append((i,j))\n",
    "\n",
    "    for op, a_start, a_end, b_start, b_end in cz_it.get_opcodes():\n",
    "      frag_cz = {cz_sent[a_start:a_end]}\n",
    "      frag_it = {it_sent[b_start:b_end]}\n",
    "\n",
    "      if op == \"equal\":\n",
    "        for item in frag_cz:\n",
    "          cz_it_sent += item\n",
    "      elif op == \"replace\":\n",
    "        for i in frag_cz:\n",
    "          for j in frag_it:\n",
    "            cz_it_sent.append((i,j))\n",
    "\n",
    "    for i, item in enumerate(zip(it_fi_sent, fi_cz_sent, cz_it_sent)):\n",
    "      it_fi_item = item[0]\n",
    "      fi_cz_item = item[1]\n",
    "      cz_it_item = item[2]\n",
    "\n",
    "\n",
    "      if isinstance(it_fi_item, str) and isinstance(\n",
    "        fi_cz_item, str) and isinstance(cz_it_item, str): #when all agree\n",
    "          final_output += it_fi_item\n",
    "\n",
    "\n",
    "      elif isinstance(it_fi_item, tuple) and isinstance(\n",
    "          fi_cz_item, tuple) and isinstance(cz_it_item, tuple): #when none agree\n",
    "          it_choice = it_fi_item[0]\n",
    "          fi_choice = fi_cz_item[0]\n",
    "          cz_choice = cz_it_item[0]\n",
    "\n",
    "          c_dict = choice_dict([it_choice, fi_choice, cz_choice])\n",
    "          final_choice = make_choice(c_dict)\n",
    "\n",
    "          final_output += final_choice\n",
    "\n",
    "      elif isinstance(it_fi_item, tuple) and isinstance(fi_cz_item, tuple):\n",
    "        it_choice = it_fi_item[0]\n",
    "        fi_choice = fi_cz_item[0]\n",
    "        cz_choice = cz_it_item\n",
    "\n",
    "        c_dict = choice_dict([it_choice, fi_choice, cz_choice])\n",
    "        final_choice = make_choice(c_dict)\n",
    "\n",
    "        final_output += final_choice\n",
    "\n",
    "      elif isinstance(fi_cz_item, tuple) and isinstance(cz_it_item, tuple):\n",
    "        it_choice = it_fi_item\n",
    "        fi_choice = fi_cz_item[0]\n",
    "        cz_choice = cz_it_item[0]\n",
    "\n",
    "        c_dict = choice_dict([it_choice, fi_choice, cz_choice])\n",
    "        final_choice = make_choice(c_dict)\n",
    "\n",
    "        final_output += final_choice\n",
    "\n",
    "      elif isinstance(cz_it_item, tuple) and isinstance(it_fi_item, tuple):\n",
    "        it_choice = it_fi_item[0]\n",
    "        fi_choice = fi_cz_item\n",
    "        cz_choice = cz_it_item[0]\n",
    "\n",
    "        c_dict = choice_dict([it_choice, fi_choice, cz_choice])\n",
    "        final_choice = make_choice(c_dict)\n",
    "\n",
    "        final_output += final_choice\n",
    "\n",
    "      elif isinstance(cz_it_item, tuple):\n",
    "        it_choice = it_fi_item\n",
    "        fi_choice = fi_cz_item\n",
    "        cz_choice = cz_it_item[0]\n",
    "\n",
    "        c_dict = choice_dict([it_choice, fi_choice, cz_choice])\n",
    "        final_choice = make_choice(c_dict)\n",
    "\n",
    "        final_output += final_choice\n",
    "\n",
    "      elif isinstance(fi_cz_item, tuple):\n",
    "        it_choice = it_fi_item\n",
    "        fi_choice = fi_cz_item[0]\n",
    "        cz_choice = cz_it_item\n",
    "\n",
    "        c_dict = choice_dict([it_choice, fi_choice, cz_choice])\n",
    "        final_choice = make_choice(c_dict)\n",
    "\n",
    "        final_output += final_choice\n",
    "\n",
    "      elif isinstance(it_fi_item, tuple):\n",
    "        it_choice = it_fi_item[0]\n",
    "        fi_choice = fi_cz_item\n",
    "        cz_choice = cz_it_item\n",
    "\n",
    "        c_dict = choice_dict([it_choice, fi_choice, cz_choice])\n",
    "        final_choice = make_choice(c_dict)\n",
    "\n",
    "        final_output += final_choice\n",
    "\n",
    "  else: #only 2 usabe sents\n",
    "      it_fi = SequenceMatcher(None, it_sent, fi_sent)\n",
    "      it_fi_sent = []\n",
    "\n",
    "      for op, a_start, a_end, b_start, b_end in it_fi.get_opcodes():\n",
    "        frag_it = {it_sent[a_start:a_end]}\n",
    "        frag_fi = {fi_sent[b_start:b_end]}\n",
    "\n",
    "        if op == \"equal\":\n",
    "          for item in frag_it:\n",
    "            final_output += item\n",
    "\n",
    "        elif op == \"replace\":\n",
    "          for i in frag_it:\n",
    "            for j in frag_fi:\n",
    "              final_output += str(random.choice([i, j]))\n",
    "\n",
    "\n",
    "  return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: könyökhajlásba kapta a maláj nyakát, és a dereka mellé szorította.\n",
      "Final:  konak kokat ail yscome ally sorpzata\n",
      "It: fognak hokage rock ott alig north il scederecome ally sorozata\n",
      "Fi: könjukhoilays bok loptak milan sokat aisha derekomälli sor torta\n",
      "Cz: konok honlap bo costa hol sokat i saderecomely sor torta\n",
      "*************************\n",
      "Reference: de uram teremtőm, hogy megtépázta a zuhogó eső meg a vad szél!\n",
      "Final:  ha uram turemt htärtag p t ihogy s ogombot sag\n",
      "It: ha uram teremt hold mik tag part sehogy sh gombot said\n",
      "Fi: jo uram tärämtööm hit miatti post ahogy ss maga vonni\n",
      "Cz: da uram tartom hoz mak te part oshogo ashumagowod sem\n",
      "*************************\n",
      "Reference: azt te tudod a legjobban, apjuk!\n",
      "Final:  astan apeuk\n",
      "It: ho start da nagyon ap uk\n",
      "Fi: asteetutotäläkiopan apjuk\n",
      "Cz: o este tu oldala gibson of jut\n",
      "*************************\n",
      "Reference: a kerék is jobban forog, ha kenik.\n",
      "Final:  ak i fogok hakni\n",
      "It: a ke rak six fogok haladni\n",
      "Fi: akäriakis jobban fogok hatni\n",
      "Cz: o marie ki jobban fogok hocanik\n",
      "*************************\n",
      "Reference: az meg ott egy újságfoszlány!\n",
      "Final:  aa  otta tal\n",
      "It: osama gotta bush ak first line\n",
      "Fi: ame lotte aisha foglal\n",
      "Cz: some got te jussak foglal\n",
      "*************************\n",
      "Reference: azt gondolták: most jön az ágyú!\n",
      "Final:  gonooi tetteonasadiu\n",
      "It: gondol tecmostionasadiu\n",
      "Fi: antonio lettek mostoha sääjuu\n",
      "Cz: a s gondol tak most je na zulu\n",
      "*************************\n",
      "Reference: ahá!\n",
      "Final:  ah\n",
      "It: aah\n",
      "Fi: ahol\n",
      "Cz: aha\n",
      "*************************\n",
      "Reference: az ám, de hol vannak a bérkocsik?\n",
      "Final:  slvonohoberkovik\n",
      "It: oda da hulvonoko berkochik\n",
      "Fi: sem täholvannakaberkotsik\n",
      "Cz: a nem ahol van na kabir konok\n",
      "*************************\n",
      "Reference: jártam már így.\n",
      "Final:  mata mar \n",
      "It: mata marie\n",
      "Fi: kazetta marad\n",
      "Cz: jo tam mm re\n",
      "*************************\n",
      "Reference: én tudni fogom.\n",
      "Final:  ennnifogot\n",
      "It: engedni fogom\n",
      "Fi: en tutnifokam\n",
      "Cz: je jen tudni fogom\n",
      "*************************\n",
      "Reference: maguknak befellegzett!\n",
      "Final:  maguk na bgfkllnett\n",
      "It: maguk nagy befellegzett\n",
      "Fi: maguk na bäfällänsett\n",
      "Cz: maguk nakbefe lehet\n",
      "*************************\n",
      "Reference: a szerkesztéshez nem szükséges internet-kapcsolat, így számomra egyszerűbb az új cikkek írása.\n",
      "Final:  sarka sts has neas internet kaptuitsikkira\n",
      "It: sarka stace has nem sukcegach internet kaptunk itsamomretzaruposwizkkirash\n",
      "Fi: aserkästis has namsykikes internet kapcsolat is moira etserypas uitsikkä kira\n",
      "Cz: a srcaste is he nem sue as internet kapcsolat jog sámomra ette rum a z uk cica íráša\n",
      "*************************\n",
      "Reference: ez csak egy zavaró tévedés.\n",
      "Final:  s ciochezzavaroate evans\n",
      "It: e ciochezzavaro te evans\n",
      "Fi: is akit savaruutii v is\n",
      "Cz: s čakejt a daru ty ji vedd\n",
      "*************************\n",
      "Reference: ez beteges, de te nem vagy az.\n",
      "Final:  amber ten tags\n",
      "It: amber t gage the then hamu boys\n",
      "Fi: äsbertägäshdä ten vajas\n",
      "Cz: esbetagež date nem okoz\n",
      "*************************\n",
      "Reference: elindultam veled a messzi világba, de ha igazán szeretsz, vigyél vissza, kérlek, vigyél vissza!\n",
      "Final:  äliniultran vllaan ssiviae da igmnserezsdd elvis kerek vi dièagra\n",
      "It: allindultran vala i domessivi lamb da igoznserez vidd elvis kerek vi dièalvissa\n",
      "Fi: älintultaan väletomässi viagra dana igasänseret vijelvissa kerek vijelvissa\n",
      "Cz: elindul tam vele dom savi la-be da ho i gozserec visel sok jelek visel vita\n",
      "*************************\n",
      "Reference: nem, te csak magyarázatot adtál.\n",
      "Final:  nem eac jresa uta tal\n",
      "It: nem tachavmo teresa jut a tal\n",
      "Fi: nem jack morzsa utat till\n",
      "Cz: nem tara v maďěará a tud utal\n",
      "*************************\n",
      "Reference: mit tudja ezt egy likőrösállvány?\n",
      "Final:  ittelil cicero hatvör\n",
      "It: mi tu delta il cicero hatvan\n",
      "Fi: itt jästelikörsävän\n",
      "Cz: my tud teli korosálvaň\n",
      "*************************\n",
      "Reference: ne igyál előre a medve bőrére.\n",
      "Final:  nem  parlyra\n",
      "It: media la sora ma va partra\n",
      "Fi: nem jolly lyörää medve pyyriireä\n",
      "Cz: na ji dala fura maga bulira\n",
      "*************************\n",
      "Reference: bekapcsolta a gépet és megvárta, amíg beindul.\n",
      "Final:  bankok chloete pert   sbaindul\n",
      "It: bankok chloe e pert i schmackbert omigbaindoul\n",
      "Fi: bäkaptsoeltaa igent is megvert a mig beindul\n",
      "Cz: ba capčoval tegye pat is magyar o mig ban doyle\n",
      "*************************\n",
      "Reference: margit visszaköszönt, és megindult a lifthez.\n",
      "Final:  mar tissicksson esem gin dä\n",
      "It: morgan wissuckorson e csemege in delta lifthez\n",
      "Fi: mar kit vissackassant eshmägin tudta lift\n",
      "Cz: margtwis caclesont e smagindulta lev has\n",
      "*************************\n",
      "Reference: az üzletrész mértéke a tagok törzsbetétjéhez igazodik.\n",
      "Final:  okosllttek i ismertek smeoguptes hasigasodi \n",
      "It: okos lettek i ismertek ho toguptushbtkyehasigasodich\n",
      "Fi: asyyslähteri ismertek avagy törsbäte keres hatodik\n",
      "Cz: ozuslatri s ortega o maguk tuřbaty texas iga sonic\n",
      "*************************\n",
      "Reference: el sem beszélte nénjeinek, mit látott odafönn a földi világban.\n",
      "Final:  lshem an barti nmeigna rain\n",
      "It: asher an bartlet nignainmitlatoraphnfeldivilakpon\n",
      "Fi: älshämbässieltä in mein mit lett odafenn fedi irakban\n",
      "Cz: l sam bevitte jan annak mit lÃ¡tod dave na folyik vi abban\n",
      "*************************\n",
      "Reference: fiúk, megvan.\n",
      "Final:  lyuk n\n",
      "It: lyuk nagyon\n",
      "Fi: tuck megvan\n",
      "Cz: fiuk ma gwan\n",
      "*************************\n",
      "Reference: nagyon segítőkész vagy.\n",
      "Final:  no j sharishägi ke\n",
      "It: no you sharif kezdi\n",
      "Fi: na jon shägitöö kedvez\n",
      "Cz: napon vak ja tu ki swat\n",
      "*************************\n",
      "Reference: fából vaskarika.\n",
      "Final:  fabio lsh cariaa\n",
      "It: fabio bush carina\n",
      "Fi: pääpool voskarika\n",
      "Cz: fábou lvaškarika\n",
      "*************************\n",
      "Reference: kicsit rendetlen?\n",
      "Final:  ki trtndi kal\n",
      "It: chi ki trendi kaland\n",
      "Fi: ki mit ränvätlän\n",
      "Cz: ki ten ve ten\n",
      "*************************\n",
      "Reference: aztán csupasz lábbal megtilolta a csalánt, és nekilátott szőni.\n",
      "Final:  von ctu pal mouplt oldala i snackyla hozzon\n",
      "It: aston chu postrappal motelt oldala i snackyla hozzon\n",
      "Fi: vastag csupa pal mäktilolta atsalänt ishnäkilät ot esni\n",
      "Cz: gaston csupa slápal nagy lova a halat is nacilatoceuny\n",
      "*************************\n",
      "Reference: simon bíró hajtja a lovat.\n",
      "Final:  shimaibro hhaalovat\n",
      "It: shimambro heikealovat\n",
      "Fi: shimanbii roo hacker lovat\n",
      "Cz: vi mm but noha i těalovat\n",
      "*************************\n",
      "Reference: a személyiségi jogokat személyesen lehet érvényesíteni.\n",
      "Final:  asem ishegioggo gake teriniec\n",
      "It: asszem ishegiougo hozzam change terminiecitani\n",
      "Fi: asemeishe giorgio kate miss lehet erin ja nyitni\n",
      "Cz: mi jaime giogokacemi je čenhad irviněšíteny\n",
      "*************************\n",
      "Reference: az ő kedvükért még a bot is megelevenedett.\n",
      "Final:  eu k e me shmegala veee lett\n",
      "It: eu kedwukye megadni schmegala vele lett\n",
      "Fi: as kädvykeet mik potishmäkälä vezetett\n",
      "Cz: az catwuc je maga botot magalevwenedet\n",
      "*************************\n",
      "Reference: ez nem más, mint hamupipőke.\n",
      "Final:  a unalmas mimhomoham\n",
      "It: a unalmas mit homo burke\n",
      "Fi: äsnämmäs mini thamopipökää\n",
      "Cz: aznap meg mit ho mu picike\n",
      "*************************\n",
      "Reference: azt tetted még csak jól!\n",
      "Final:  o siee t  iake\n",
      "It: o siet tad make tuck doyle\n",
      "Fi: as te t mi jake\n",
      "Cz: o stb tad mik sok jol\n",
      "*************************\n",
      "Reference: úgy látszik ennek a nagy világcsavargónak a vére ütött ki rajtam.\n",
      "Final:  uollarts che annasaviera ustkir\n",
      "It: tollat che anna can ogre vilaccio vagina kolera uttkiritham\n",
      "Fi: udlartsikännä kanos voltak savargunakavierä ytötkiraitam\n",
      "Cz: udlacican national iv nak chavargu jakob rumot ki roy tom\n",
      "*************************\n",
      "Reference: szalonkabát!\n",
      "Final:  aalonoabk\n",
      "It: falon cabe\n",
      "Fi: salonkabäät\n",
      "Cz: alan ha be\n",
      "*************************\n",
      "Reference: maga mondta!\n",
      "Final:  magamon\n",
      "It: maga mondta\n",
      "Fi: magamon\n",
      "Cz: magamon\n",
      "*************************\n",
      "Reference: aki sokat ígér, keveset ad.\n",
      "Final:  aki svaset od\n",
      "It: hoki sokat igen tavasz et oda\n",
      "Fi: aki sokat igen keveset ad\n",
      "Cz: oly sokat egan javaslat ot\n",
      "*************************\n",
      "Reference: pillantása végigfutott rajta tetőtől talpig.\n",
      "Final:  pilill toaaitatetter titarpii ve\n",
      "It: pilonteshavigi fu totraitatetter turtarpig\n",
      "Fi: pillanat two haiti vetetni tätätöötöötarpik\n",
      "Cz: pi lantáša vi gicuta traitata toto el ig\n",
      "*************************\n",
      "Reference: ezért jobb lesz, ha elhagyom a várost, és nyugodtabb helyre vitorlázom.\n",
      "Final:  ashtobaestohros nÃ¡poannyira vitorgott\n",
      "It: ashton bass hartodiomabaros e newport annyira vitorlasom\n",
      "Fi: asietiobless halhatok vÃ¡rost e snugottap hiro victor lakom\n",
      "Cz: siet wales hol ho roma várošt innen goran hiravý tor lakom\n",
      "*************************\n",
      "Reference: egy rendőrtiszt előrelépett.\n",
      "Final:  e g granddtistrti lehet\n",
      "It: a grand autista akkora lehet\n",
      "Fi: e grändörtist olyan lopott\n",
      "Cz: brando orvost a fura li pet\n",
      "*************************\n",
      "Reference: attól félek, hogy ketten kevesen leszünk hozzá.\n",
      "Final:  a volt-e coletten je \n",
      "It: otto volt-e colette enyhe a vescianlec un jose\n",
      "Fi: attÃ³l fieläkhot ketten kävässällä synkhossää\n",
      "Cz: a hol falak hoďkattanka ve sanlesinchose\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "all_final = []\n",
    "final_ref = []\n",
    "\n",
    "# final_transcript_fi, final_transcript_it, final_transcript_cs\n",
    "\n",
    "# for item in enumerate(zip(it, fi, cs, ref)): #this takes lists (of output)\n",
    "for item in enumerate(zip(final_transcript_it, final_transcript_fi, final_transcript_cs, ref)): #this takes lists (of output)\n",
    "    it_sent = item[1][0]\n",
    "    fi_sent = item[1][1]\n",
    "    cz_sent = item[1][2]\n",
    "    ref_sent = item[1][3]\n",
    "\n",
    "    if it_sent[0] == \" \":\n",
    "        it_sent = it_sent[1:]\n",
    "    if it_sent[-1] == \" \":\n",
    "        it_sent = it_sent[:-1]\n",
    "\n",
    "    if fi_sent[0] == \" \":\n",
    "        fi_sent = fi_sent[1:]\n",
    "    if fi_sent[-1] == \" \":\n",
    "        fi_sent = fi_sent[:-1]\n",
    "\n",
    "    if cz_sent[0] == \" \":\n",
    "        cz_sent = cz_sent[1:]\n",
    "    if cz_sent[-1] == \" \":\n",
    "        cz_sent = cz_sent[:-1]\n",
    "\n",
    "    a = len(it_sent)\n",
    "    b = len(fi_sent)\n",
    "    c = len(cz_sent)\n",
    "\n",
    "    percent_diff = (max(a, b, c)-min(a, b, c))/max(a, b, c) #between longest and shortest input\n",
    "\n",
    "    if percent_diff > .5:\n",
    "        shortest = min(a, b, c)\n",
    "        if a == shortest:\n",
    "            final_output = sentence_processing(fi_sent, cz_sent)\n",
    "            #print(\"Italian\")\n",
    "        if b == shortest:\n",
    "            final_output = sentence_processing(it_sent, cz_sent)\n",
    "            #print(\"Finnish\")\n",
    "        if c == shortest:\n",
    "            final_output = sentence_processing(it_sent, fi_sent)\n",
    "            #print(\"Czech\")\n",
    "\n",
    "    else:\n",
    "        final_output = sentence_processing(it_sent, fi_sent, cz_sent, ref_sent)\n",
    "\n",
    "\n",
    "    final_ref.append(ref_sent)\n",
    "    all_final.append(final_output)\n",
    "    print(f\"Reference: {ref_sent}\")\n",
    "    print(f\"Final: {final_output}\")\n",
    "    print(f\"It: {it_sent}\")\n",
    "    print(f\"Fi: {fi_sent}\")\n",
    "    print(f\"Cz: {cz_sent}\")\n",
    "    print(\"*\"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "CHARS_TO_IGNORE = [\",\", \"?\", \"¿\", \".\", \"!\", \"¡\", \";\", \"；\", \":\", '\"\"', \"%\", '\"', \"�\", \"ʿ\", \"·\", \"჻\", \"~\", \"՞\",\n",
    "                   \"؟\", \"،\", \"।\", \"॥\", \"«\", \"»\", \"„\", \"“\", \"”\", \"「\", \"」\", \"‘\", \"’\", \"《\", \"》\", \"(\", \")\", \"[\", \"]\",\n",
    "                   \"{\", \"}\", \"=\", \"`\", \"_\", \"+\", \"<\", \">\", \"…\", \"–\", \"°\", \"´\", \"ʾ\", \"‹\", \"›\", \"©\", \"®\", \"—\", \"→\", \"。\",\n",
    "                   \"、\", \"﹂\", \"﹁\", \"‧\", \"～\", \"﹏\", \"，\", \"｛\", \"｝\", \"（\", \"）\", \"［\", \"］\", \"【\", \"】\", \"‥\", \"〽\",\n",
    "                   \"『\", \"』\", \"〝\", \"〟\", \"⟨\", \"⟩\", \"〜\", \"：\", \"！\", \"？\", \"♪\", \"؛\", \"/\", \"\\\\\", \"º\", \"−\", \"^\", \"ʻ\", \"ˆ\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "chars_to_ignore_regex = f\"[{re.escape(''.join(CHARS_TO_IGNORE))}]\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def extract_text(batch):\n",
    "  text = batch[\"text\"]\n",
    "  batch[\"text\"] = re.sub(chars_to_ignore_regex, \"\", text.lower())\n",
    "  return batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "final_ref_proccesed = []\n",
    "\n",
    "for sent in final_ref:\n",
    "    final_ref_proccesed.append(re.sub(chars_to_ignore_regex, \"\", sent))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wer = load_metric(\"wer\")\n",
    "cer = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_transcript_fi, final_transcript_it, final_transcript_cs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wer_score = 100 * wer.compute(predictions=all_final, references=final_ref_proccesed)\n",
    "cer_score = 100 * cer.compute(predictions=all_final, references=final_ref_proccesed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"WER: {wer_score:.2f}%\")\n",
    "print(f\"CER: {cer_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wer_score = 100 * wer.compute(predictions=final_transcript_it, references=final_ref_proccesed)\n",
    "cer_score = 100 * cer.compute(predictions=final_transcript_it, references=final_ref_proccesed)\n",
    "\n",
    "print(f\"WER IT: {wer_score}%\")\n",
    "print(f\"CER IT: {cer_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wer_score = 100 * wer.compute(predictions=predicted_sentences_fi[:40], references=final_ref_proccesed)\n",
    "cer_score = 100 * cer.compute(predictions=predicted_sentences_fi[:40], references=final_ref_proccesed)\n",
    "\n",
    "print(f\"WER FI: {wer_score:.2f}%\")\n",
    "print(f\"CER FI: {cer_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wer_score = 100 * wer.compute(predictions=final_transcript_cs, references=final_ref_proccesed)\n",
    "cer_score = 100 * cer.compute(predictions=final_transcript_cs, references=final_ref_proccesed)\n",
    "\n",
    "print(f\"WER CS: {wer_score}%\")\n",
    "print(f\"CER CS: {cer_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}